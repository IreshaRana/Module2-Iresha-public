{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "784ad060-e6a5-443e-b3d1-ed7ab1138f6c",
   "metadata": {},
   "source": [
    "# Application\n",
    "This is about exploratory data analysis of product_a.csv. This is the only dataset this customer has agreed to expose. The customer would not provide more information until we produce some insights.\n",
    "Add headers or comments with the complete questions asked in the code or jupyter notebook so that we can locate your approach efficiently.dex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87334747-eec4-48a4-8574-9c964714674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing \n",
    "!pip install ydata-profiling  # Installing ydata profiling as pandas profiling is deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3d313-a949-4dfb-bbd3-dbc44b335b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import kaleido\n",
    "import plotly.graph_objs as go\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb81db-067b-4789-b8db-e6397443332a",
   "metadata": {},
   "source": [
    "## 1. Question 1\n",
    "Import product_a.csv dataset into python pandas data frame df_product_a. The first column is the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca18ab6d-dc5d-4b23-8c37-2f9e75a08059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the csv file taking the first column as index\n",
    "#data = pd.read_csv('C:/Iresha_Code/module2/product_a.csv',index_col=0)\n",
    "data = pd.read_csv('C:/Iresha_Code/module2/product_a.csv')\n",
    "\n",
    "# Create a pandas dataframe\n",
    "df_original = pd.DataFrame(data)\n",
    "df_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d7541-eafe-4d02-9d17-3a5d74427649",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Convert date_w field to a suitable datetime data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c7633-c93c-4830-b41e-85899ab06f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the existing data type\n",
    "df_original['date_w'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e53a1-72ff-488c-a906-2a9acb97643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert to a datetime data type\n",
    "df_original['date_w']=pd.to_datetime(df_original['date_w'])\n",
    "\n",
    "\n",
    "# Rename the df, after data type correction\n",
    "df_c1=df_original\n",
    "df_c1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784798c5-630d-4839-b1f3-e1cac28faa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data type change\n",
    "df_c1['date_w'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d20bb3a-7433-4a36-b305-fe51dd2d7a1d",
   "metadata": {},
   "source": [
    "## Additional - data check 1\n",
    "To get a better understanding of the dataset, I filtered for one location and sorted by the date_w column. The results indicate\n",
    "- date_w values are 7 days apart\n",
    "- Each record gives unit price, total_vol, plu volumes, bag sizes and type for each location, for each day/week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623d0aa-b22f-497d-aec0-8d1b3a8d5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows for Albany location\n",
    "df_Alb=df_c1[df_c1['location']== 'Albany']\n",
    "\n",
    "# Sort by date_w\n",
    "df_Alb_sort=df_Alb.sort_values('date_w')\n",
    "df_Alb_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26eb1e3-3468-4c0f-be5c-04c5e253b711",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Values of the year column do not match with the values of the date_w column. Correct the values of the year column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b041e9-0c18-44ae-9933-2f900a89f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from the date_w column and use that to replace values in the year column\n",
    "df_c1['year']=df_c1['date_w'].dt.year\n",
    "\n",
    "# Rename df after year column correction\n",
    "df_c2=df_c1\n",
    "df_c2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6c3b57-c5bd-49fd-83f3-3a353ceaf223",
   "metadata": {},
   "source": [
    "## Additional - data check 2\n",
    "Apart from the changes to date_w and year columns, I did some further data chekcking/cleaning before creating statistics.  \n",
    "### Check for any missing values\n",
    "- After running dropna, the number of rows has not changed, still 18,249. So there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5f254-079d-4dbc-9fea-bf8810ad4f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for columns with missing values\n",
    "df_c2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2abe89-c2fe-44e0-9ae4-df5bdc48f2b6",
   "metadata": {},
   "source": [
    "#### Checking data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd3c103-65ff-43d4-9c0b-65df22f890db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ing data types of all fields\n",
    "df_c2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa51aba-84fc-4585-8793-3b02a6710927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing data types of volume and bag size fiels to integer \n",
    "df_c2[['total_vol','plu1','plu2','plu3','bags_t','bags_s','bags_l','bags_lx']]=df_c2[['total_vol','plu1','plu2','plu3','bags_t','bags_s','bags_l','bags_lx']].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24eb7e2-07f9-47a9-bb4f-c16a17b3b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify change of data types\n",
    "df_c2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44432c3f-4935-406e-9eca-0bd91bc25e46",
   "metadata": {},
   "source": [
    "#### Checking whether totals match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed2eee-749f-458f-a532-3b85662fa318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether total bags(bags_t) is the sum of small, large and lx bags. If false all rows match. \n",
    "\n",
    "not(df_c2['bags_t'] == df_c2['bags_s']+ df_c2['bags_l']+ df_c2['bags_lx']).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c1de6-626d-49ba-9275-c7fa35e1ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting bags_t\n",
    "\n",
    "df_c2['bags_t']= df_c2['bags_s']+ df_c2['bags_l']+ df_c2['bags_lx']\n",
    "df_c2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c50fa5f-16d7-43aa-b96d-d62ee8eaf927",
   "metadata": {},
   "source": [
    "#### Checking unique values of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68592b9-ff4d-4dea-896b-3c460e0a0d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check type\n",
    "unique_type=df_c2['type'].unique()\n",
    "unique_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0296a44-feb2-4da7-ad1b-52ad72125a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check location\n",
    "unique_location=df_c2['location'].unique()\n",
    "unique_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47321eb9-82bc-4cc9-bca8-7bc4c07918e2",
   "metadata": {},
   "source": [
    "#### Removing some rows and columns before calculating statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1df8ce-a008-416a-8ede-60e1337dc917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows where location is TotalUS\n",
    "df_c3=df_c2[df_c2['location']!='TotalUS']\n",
    "df_c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e5ee6-de19-4255-aff9-fdf220d51c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 2nd column\n",
    "df_c4=df_c3.drop(columns=['Unnamed: 0'])\n",
    "df_c4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ee923-a91b-4304-ac07-e5634697db68",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "For the numeric columns, create df_stats with the following details from df_product_a.\r\n",
    "Columns of df_stats:\r\n",
    " field_name, minimum, maximum, mean, standard deviation, variance, mode, median, 0th, 10th, 20th ... 90th, 100th percentiles, 1st, 2nd and 3rd quartiles, interquartile distance, skewness and kurtosis.\r\n",
    "\r\n",
    "Theory: Discuss the relationships between the fields of df_stats. For example, the 2nd quartile and the median are the same.\r\n",
    "Discuss how the columns of df_stats are useful in data analysis.\r\n",
    "Analyse the data based on your discussion and explain the results. What are the notable features of the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ffc160-9902-4f98-a271-a19b353f24fc",
   "metadata": {},
   "source": [
    "### Calculating statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5033dc-3f4c-41dd-abb3-658990b0c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe to include only number fields\n",
    "df_numeric=df_c4.select_dtypes(include=['number'])\n",
    "df_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d296f-272d-41d9-82d1-d7ad6da4bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "min=df_numeric.min()\n",
    "max=df_numeric.max()\n",
    "mean=df_numeric.mean()\n",
    "std=df_numeric.std()\n",
    "var=df_numeric.var()\n",
    "median=df_numeric.median()\n",
    "q1=df_numeric.quantile(0.25)\n",
    "q2=df_numeric.quantile(0.5)\n",
    "q3=df_numeric.quantile(0.75)\n",
    "iqr=q3-q1\n",
    "skew=df_numeric.skew()\n",
    "kurt=df_numeric.kurt()\n",
    "\n",
    "# Create a new dataframe for statistics\n",
    "df_stats= pd.DataFrame({\n",
    "    'min':min,\n",
    "    'max':max,\n",
    "    'mean':mean,\n",
    "    'median':median,\n",
    "    'std':std,\n",
    "    'var':var,\n",
    "    'q1':q1,\n",
    "    'q2':q2,\n",
    "    'q3':q3,\n",
    "    'iqr':iqr,\n",
    "    'skew':skew,\n",
    "    'kurt':kurt\n",
    "    \n",
    "})\n",
    "\n",
    "df_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc50c6f-0984-4001-84dd-968d531ad243",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=df_numeric.mode()  # The output suggests that all fields are uni-modal expect for total_vol which is tri-modal\n",
    "mod  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd18d8-a22e-4878-abb7-c00ee094e133",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "#### Relationship between fields of statistics\n",
    "- Median is the same as the 2nd quartile (q2).\n",
    "- Both var and std measure spread from the mean.\n",
    "- Std is the square root of var.\n",
    "- Interquartile range, iqr = q3-q1\n",
    "- A positive skew means that the mean>median>mode.\n",
    "\n",
    "#### How the columns are useful for data analysis\n",
    "- The difference between max and min give the range.\n",
    "- Mean is the average.\n",
    "- When the values and ordered ascending, median is the central value.\n",
    "- q1 indicates 25%, q2 50% and q3 75%. \n",
    "- A positive skew means that the mean>median>mode. \n",
    "- A negative skew means mean<median<mode.\n",
    "- If kurt>3, this means the distribution has a heavy tail and a sharp peak, compared to a normal distribution.\n",
    "- If kurt<3, the distribution has light tails and a flat peak, compared to a normal distribution.\n",
    "\n",
    "#### Noteable features of the dataset\n",
    "- The unit price is mostly concentrated around the mean with few outliers (as kurt is closer to zero, light tail).\n",
    "- However, all the other variables plu1, plu2, plu3, bags_t, bags_s, bags_l, bags_lx indicate having extreme values (as kurt >> 3). \n",
    "- In terms of the sizes of bags, small bags are used more, with an average of 116k (per week)  compared to 34k for large bags and 2k for extra large bags. (comparing the mean values)\n",
    "- Further, extra large bag sizes were not used in a majority of weeks (as q2 value is zero).\n",
    "- The variables plu1, plu2, plu3, bags_t, bags_s, bags_l, bags_lx all have zero mode, which could be the reason for all those variables having a positve skew. This needs to be further investigated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83855e-c426-41a2-bf4e-42b9f038d023",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "### Pearson correlation matrix\r\n",
    "Calculate the Pearson correlation matrix (it is a square matrix) between all the possible fields. What are the conclusions yo make??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2daf9e6-1fa3-4188-b7e7-e057540922d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select fields\n",
    "col_p=['price', 'total_vol', 'plu1', 'plu2', 'plu3', 'bags_t', 'bags_s', 'bags_l', 'bags_lx']\n",
    "\n",
    "# Calculate pearson correlation matrix\n",
    "corr_matrix= df_numeric[col_p].corr(method='pearson')\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63c80e-9351-45a9-8625-32c72482bdcc",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "- If the unit price goes up, the other fields of total volume, the volume of each plu, total bag size and each individual bag size per transaction could slightly go down. If the unit price goes down, the same fields could slights go up. However, this increase or decrease is not strong or consistent.  \n",
    "- There is a extremely strong relationship between the small bags and the total bags. When small bags increase there is a very high change that total bags also increase, and vice versa.\n",
    "- Also, when there is another strong relationship betweem small bags and total volume. When small bags increase there is a very high change that total volume also increase, and vice versa.\n",
    "- This suggests that when there is an increase or decrease in total colume and the total bags, small bags would also increase or decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6783e1c-4f58-49a0-9b4d-cd68c97c24f3",
   "metadata": {},
   "source": [
    "### Spearman correlation matrix\n",
    "Calculate Spearman’s Rank correlation matrix (it is a square matrix) between all the possible fields. What are the conclusions you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d54db4-37e2-46a5-ba08-4651f5376d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select fields\n",
    "col_p=['price', 'total_vol', 'plu1', 'plu2', 'plu3', 'bags_t', 'bags_s', 'bags_l', 'bags_lx']\n",
    "corr_r_matrix= df_numeric[col_p].corr(method='spearman')\n",
    "corr_r_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef723db-2405-47e4-aa63-357cb3de9ec5",
   "metadata": {},
   "source": [
    "Conclusions\n",
    "- Price has a linear inverse relationship with other variables, that is when price goes up, the other volume and bag size related variables go down and vice versa. The strength of thsse relationships are moderate.\n",
    "- There is a extremely strong relationship between the small bags and the total bags. When small bags increase there is a very high change that total bags also increase, and vice versa.\n",
    "- Also, when there is another strong relationship betweem small bags and total volume. When small bags increase there is a very high change that total volume also increase, and vice versa.\n",
    "- This suggests that when there is an increase or decrease in total colume and the total bags, small bags would also increase or decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03223f1-a5d8-472d-bfb4-13ddf7e689e2",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Draw a Plotly scatter matrix plot for df_product_a. What are the conclusions you can make using the analysis so far?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f144c6c-afa7-406d-9005-65692612def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "df_c4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f69d720-ac73-4ec7-9540-123c867d4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter matrix for price and volume related data\n",
    "fig1=px.scatter_matrix(df_c4, dimensions=['price', 'total_vol', 'plu1', 'plu2', 'plu3'], title='Scatter Matrix for price and volumes')\n",
    "\n",
    "# Create a scatter matrix for price and bag size related data\n",
    "fig2=px.scatter_matrix(df_c4, dimensions=['price', 'bags_s', 'bags_l', 'bags_lx', 'bags_t'], title='Scatter Matrix for price and bag sizes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b7105-b6e7-4d22-a9c4-f0053096145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1.write_image('ScatterMatrix1_ProductA.png')\n",
    "fig2.write_image('ScatterMatrix2_ProductA.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b683a4c0-2225-4cd4-80be-5d6da0bd4f3f",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "- When considering volumes,\n",
    "    - The variation of total and individual plu volumes against unit price is similar. For lower prices, there are higher volumes, but the volumes go down when the unit price goes up.\n",
    "    - When total volume goes up, plu 1 and plu2 show a generally increasing trend, but the relationship between total volume and plu3 is not that clear. This suggests that plu1 and plu2 are stronger predictors of total volume than plu 3.\n",
    "  \n",
    "- When considering bag sizes,\n",
    "    - The variation of the 3 bag sizes and the total bag size against unit price is similar.  For lower prices, there are higher number of bag sizes used, but the volumes go down when the unit prices go up.\n",
    "    - This relationship between bag sizes and price is similar to the one with volumes and price. Both are inverse relationships. \n",
    "    - When total bags increase, small bags and large bags also increase, but the relationship is more prominent for small bags than large bags.\n",
    "    - When total bags increase, extra large bags show a decreasing trend. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016ada32-9449-44f8-9e2d-61be5cccd5a7",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "Using Plotly, draw weekly and monthly time-series graphs of the numeric fields. Discuss your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b980e-7ae4-47a2-9065-c3f502606d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for type to confirm\n",
    "df_c4['date_w'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c05a8-dbd0-4b4c-8d62-345bbf9f39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date\n",
    "df_c4=df_c4.sort_values('date_w')\n",
    "df_c4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2facdbce-4470-4afe-80fc-e47d712fe678",
   "metadata": {},
   "source": [
    "### Weekly time-series graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba018c8d-d6e7-4597-bda1-c68513e87d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data to a weekly frequency\n",
    "df_weekly = df_c4.resample('W-Mon', on='date_w').sum().reset_index()\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_col=df_c4.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Draw line graphs for each numeric column\n",
    "for column in numeric_col:\n",
    "    fig = px.line(df_c4, x='date_w', y=column, title=f'Weekly variation of {column}')\n",
    "    fig.update_layout(xaxis_title='Date', yaxis_title=column)\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b056061-ced1-4970-bb2e-9dbdc50f82b0",
   "metadata": {},
   "source": [
    "### Monthly time-series graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc3c84-f897-432e-9dba-e91876cf8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data to a monthly frequency\n",
    "df_monthly = df_c4.resample('ME', on='date_w').sum().reset_index()\n",
    "\n",
    "numeric_col=df_c4.select_dtypes(include=['number']).columns\n",
    "\n",
    "for column in numeric_col:\n",
    "    fig = px.line(df_c4, x='date_w', y=column, title=f'Monthly variation of {column}')\n",
    "    fig.update_layout(xaxis_title='Month', yaxis_title=column)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b23da1-c9dd-48df-9a4c-8a890cfdb7a5",
   "metadata": {},
   "source": [
    "### Discussion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed40744e-1ec8-49a0-9b96-8210e03fd5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d92a9eab-e2bd-4aeb-ba77-43184d828e63",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "Draw year based location and type bar charts for the total volume using Plotly. Discuss your results.\n",
    "### Year based location bar chart for total volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e39fa6-cbc6-4664-99f5-28caf28e0bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a bar chart with multi-level x axis\n",
    "fig = go.Figure()\n",
    "\n",
    "for location in df_c4['location'].unique():\n",
    "    df_location = df_c4[df_c4['location'] == location]\n",
    "    fig.add_trace(go.Bar(\n",
    "    x=df_location['year'].astype(str),\n",
    "    y=df_location['total_vol'],\n",
    "    name=location,\n",
    "    ))\n",
    "    \n",
    "\n",
    "#Update layout to show multi-level x-axis\n",
    "fig.update_layout(\n",
    "    barmode='group',\n",
    "    xaxis_title='year',\n",
    "    yaxis_title='Total volume',\n",
    "    title='Total volume by year and location',\n",
    "    xaxis={'categoryorder':'category ascending'},\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26112dc1-9109-49fa-b48e-9b96f40ef1e8",
   "metadata": {},
   "source": [
    "### Year based type bar chart for total volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a4f58e-9a0d-4cec-9ab7-168376c7ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a bar chart with multi-level x axis\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for type in df_c4['type'].unique():\n",
    "    df_type = df_c4[df_c4['type'] == type]\n",
    "    fig.add_trace(go.Bar(\n",
    "    x=df_type['year'].astype(str),\n",
    "    y=df_type['total_vol'],\n",
    "    name=type,\n",
    "    ))\n",
    "    \n",
    "\n",
    "#Update layout to show multi-level x-axis\n",
    "fig.update_layout(\n",
    "    barmode='group',\n",
    "    xaxis_title='year',\n",
    "    yaxis_title='Total volume',\n",
    "    title='Total volume by year and type',\n",
    "    xaxis={'categoryorder':'category ascending'},\n",
    "    )\n",
    "\n",
    "fig.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03732ee-9c82-4aa3-9cc0-4ed907860260",
   "metadata": {},
   "source": [
    "### Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46143a36-8182-41fe-92dc-56f39cacd16f",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "Compare and contrast the prices of each type, each location and {location and type} combination. Visualise the results using suitable plots.\n",
    "### Price vs. type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f2db4-4d82-4125-b8fc-2578b9469bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_c4, x='type', y='price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71b94e-3d5a-4c94-80f0-0d3b85846e46",
   "metadata": {},
   "source": [
    "### Price vs. location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccadc729-fd34-47e8-9014-86d6a218588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_c4, x='location', y='price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f536ff-faae-40dc-b179-6aae01a335c4",
   "metadata": {},
   "source": [
    "### Price vs. location and type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b241d6a-8aad-4074-813a-5cd5b4d34cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_c4, x='location', y='price', color='type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66185ae7-af37-40a9-b421-07f3d34375e3",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "Install pandas_profiling package if it is not already installed. Create and display a profile report of df_product_a with pandas_profiling. (Note: you have to learn how to generate statistics with and without pandas_profiling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d29a3-e81a-4462-9da8-c3a29ce90374",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed5797-f952-4ead-886b-e9bbf6c1c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the profile report\n",
    "profile = ProfileReport(\n",
    "    df_numeric,\n",
    "    title='ProductA_ProfileReport',\n",
    "    #correlations=False\n",
    ")\n",
    "\n",
    "# Save report to a html file\n",
    "profile.to_file('Report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a675e62e-7e89-44f6-a7fc-883f963ae2a8",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "Install and try dtale https://pypi.org/project/dtale/ package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b621aa-fe73-45ea-90b2-0e18b241affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dtale \n",
    "#!pip install dtale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa0eb6-bc2c-4b51-8fc8-57e6f12cee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To verify installation\n",
    "#!pip show dtale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0574e46f-0dd9-46f6-b3fb-210d9f6c3722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dtale\n",
    "import dtale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240f23d-8aa5-441a-a10b-80efe4a0d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Launch D-Tale\n",
    "dtale_app = dtale.show(df_c4)\n",
    "dtale_app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2976c547-1753-4828-885e-b519bbe642d5",
   "metadata": {},
   "source": [
    "## Question 12\n",
    "Use https://github.com/DataDisca/geo_coordinates to retrieve longitudes and latitudes from Google, Here and ArcGIS map service providers. Record the following.\n",
    "Map Service Provider\tAddress\tLongitude\tLatitude\tResponse Time (ms)\tSuccess (1 = True, 0 = False)\n",
    "\n",
    "### Question 12.1\n",
    "Copy your data into geo_retrieval_stat_<your_git_username>.csv.\r\n",
    "The header names should be msp, address, longitude, latitude, response_time, success. Push that into your GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7014fc96-9d83-4f21-a85d-06a3900eaddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
